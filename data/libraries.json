{
  "libraries": [
    {
      "id": 1,
      "email": "aaa@yahoo.com",
      "name": "sample library 2",
      "public": true,
      "paradigms": [
        {
          "pdid": 1,
          "name": "Actor-based",
          "details": "The actor model in computer science is a mathematical model of concurrent computation that treats \"actors\" as the universal primitives of concurrent computation. In response to a message that it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received.",
          "subparadigms": []
        },
        {
          "pdid": 2,
          "name": "Class-based",
          "details": "Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance is achieved by defining classes of objects, as opposed to the objects themselves (compare prototype-based programming).",
          "subparadigms": []
        },
        {
          "pdid": 3,
          "name": "Concurrent",
          "details": "Concurrent object-oriented programming is a programming paradigm which combines object-oriented programming (OOP) together with concurrency",
          "subparadigms": []
        },
        {
          "pdid": 4,
          "name": "Object-oriented",
          "details": "Object-oriented programming (OOP) is a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods.",
          "subparadigms": [
            1,
            2,
            3
          ]
        }
      ],
      "programminglanguages": [
        {
          "plid": 1,
          "name": "Java",
          "details": "Java is a general-purpose computer programming language that is concurrent, class-based, object-oriented and specifically designed to have as few implementation dependencies as possible. It is intended to let application developers \"write once, run anywhere\" (WORA)",
          "type": "compiled"
        }
      ],
      "havings": [
        {
          "plid": 1,
          "pdid": 4
        },
        {
          "plid": 1,
          "pdid": 2
        },
        {
          "plid": 1,
          "pdid": 3
        }
      ]
    },
    {
      "id": 2,
      "email": "abc@yahoo.sample.com",
      "name": "Sample library",
      "public": true,
      "paradigms": [
        {
          "pdid": 3,
          "name": "Array-oriented",
          "details": "In computer science, array programming languages (also known as vector or multidimensional languages) generalize operations on scalars to apply transparently to vectors, matrices, and higher-dimensional arrays.\n\nArray programming primitives concisely express broad ideas about data manipulation. The level of concision can be dramatic in certain cases: it is not uncommon to find array programming language one-liners that require more than a couple of pages of Java code.[1]\n\nModern programming languages that support array programming are commonly used in scientific and engineering settings; these include Fortran 90, Mata, MATLAB, Analytica, TK Solver (as lists), Octave, R, Cilk Plus, Julia, and the NumPy extension to Python. In these languages, an operation that operates on entire arrays can be called a vectorized operation,[2] regardless of whether it is executed on a vector processor or not.",
          "subparadigms": []
        },
        {
          "pdid": 6,
          "name": "Concurrent",
          "details": "Concurrent computing is a form of computing in which several computations are executed during overlapping time periods—concurrently—instead of sequentially (one completing before the next starts). This is a property of a system—this may be an individual program, a computer, or a network—and there is a separate execution point or \"thread of control\" for each computation (\"process\"). A concurrent system is one where a computation can advance without waiting for all other computations to complete; where more than one computation can advance at the same time.[1]\n\nAs a programming paradigm, concurrent computing is a form of modular programming, namely factoring an overall computation into subcomputations that may be executed concurrently. Pioneers in the field of concurrent computing include Edsger Dijkstra, Per Brinch Hansen, and C.A.R. Hoare.",
          "subparadigms": []
        },
        {
          "pdid": 15,
          "name": "Purely functional programming",
          "details": "In computer science, purely functional programming usually designates a programming paradigm—a style of building the structure and elements of computer programs—that treats all computation as the evaluation of mathematical functions. Purely functional programing may also be defined by forbidding changing-state and mutable data.\n\nPurely functional programing consists in restricting programming to its functional paradigm.\n\nContents  [hide] \n1\tDifference between pure and not-pure functional programming\n2\tProperties of purely functional program\n2.1\tStrict versus non-strict evaluation\n2.2\tParallel computing\n2.3\tData structures\n3\tPurely functional language\n4\tReferences\nDifference between pure and not-pure functional programming[edit]\nThe exact difference between pure and impure functional programing is a matter of controversy.[1]\n\nA program is usually said to be functional when it uses some concepts of functional programming, such as first-class functions and higher-order functions.[2] However, a first-class function may use techniques from the imperative paradigm, such as arrays or input/output methods are not purely functional programs, therefore the first-class function needs not be purely functional. In fact, the earliest programming languages cited as being functional, IPL and Lisp,[3][4] were both \"impure\" functional languages by the current definition.\n\nPurely functional data structures are persistent. Persistency is required for functional programming; without it, the same computation could return different results. Functional programming may use persistent non-purely functional data structures, while those data structures may not be used in purely functional programs.\n\nProperties of purely functional program[edit]\nStrict versus non-strict evaluation[edit]\nMain article: Evaluation strategy\nAll evaluation strategy which ends on a purely functional programs returns the same result. In particular, it ensures that the programmer does not have to consider in which order programs are evaluated, since eager evaluation will return the same result than lazy evaluation. However, it is still possible that an eager evaluation may not terminate while the lazy evaluation of the same program halts.\n\nParallel computing[edit]\nPurely functional programing simplifies parallel computing[5] since two purely functional parts of the evaluation never interact.\n\nData structures[edit]\nMain article: Purely functional data structure\nPurely functional data structures are often represented in a different way than their imperative counterparts.[6] For example, array with constant-time access and update is a basic component of most imperative languages and many imperative data-structure, such as hash table and binary heap, are based on arrays. Arrays can be replaced by map or random access list, which admits purely functional implementation, but the access and update time is logarithmic. Therefore, purely functional data structures can be used in languages which are non-functional, but they may not be the most efficient tool available, especially if persistency is not required.\n\nPurely functional language[edit]\nMain article: List of programming languages by type § Pure\nA purely functional language is a language which only admits purely functional programming. Purely functional programs can however be written in languages which are not purely functional.",
          "subparadigms": []
        },
        {
          "pdid": 16,
          "name": "Functional",
          "details": "In computer science, functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions[1] or declarations[2] instead of statements. In functional code, the output value of a function depends only on the arguments that are input to the function, so calling a function f twice with the same value for an argument x will produce the same result f(x) each time. Eliminating side effects, i.e. changes in state that do not depend on the function inputs, can make it much easier to understand and predict the behavior of a program, which is one of the key motivations for the development of functional programming.\n\nFunctional programming has its roots in lambda calculus, a formal system developed in the 1930s to investigate computability, the Entscheidungsproblem, function definition, function application, and recursion. Many functional programming languages can be viewed as elaborations on the lambda calculus. Another well-known declarative programming paradigm, logic programming, is based on relations.[3]\n\nIn contrast, imperative programming changes state with commands in the source language, the most simple example being assignment. Imperative programming does have functions—not in the mathematical sense—but in the sense of subroutines. They can have side effects that may change the value of program state. Functions without return values therefore make sense. Because of this, they lack referential transparency, i.e. the same language expression can result in different values at different times depending on the state of the executing program.[3]\n\nFunctional programming languages, especially purely functional ones such as Hope, have largely been emphasized in academia rather than in commercial software development. However, prominent programming languages which support functional programming such as Common Lisp, Scheme,[4][5][6][7] Clojure,[8][9] Wolfram Language[10] (also known as Mathematica), Racket,[11] Erlang,[12][13][14] OCaml,[15][16] Haskell,[17][18] and F#[19][20] have been used in industrial and commercial applications by a wide variety of organizations. Functional programming is also supported in some domain-specific programming languages like R (statistics),[21] J, K and Q from Kx Systems (financial analysis), XQuery/XSLT (XML),[22][23] and Opal.[24] Widespread domain-specific declarative languages like SQL and Lex/Yacc use some elements of functional programming, especially in eschewing mutable values.[25]\n\nProgramming in a functional style can also be accomplished in languages that are not specifically designed for functional programming. For example, the imperative Perl programming language has been the subject of a book describing how to apply functional programming concepts.[26] This is also true of the PHP programming language.[27] C++11, Java 8, and C# 3.0 all added constructs to facilitate the functional style. The Julia language also offers functional programming abilities. An interesting case is that of Scala[28] – it is frequently written in a functional style, but the presence of side effects and mutable state place it in a grey area between imperative and functional languages.\n\nContents  [hide] \n1\tHistory\n2\tConcepts\n2.1\tFirst-class and higher-order functions\n2.2\tPure functions\n2.3\tRecursion\n2.4\tStrict versus non-strict evaluation\n2.5\tType systems\n2.6\tReferential transparency\n2.7\tFunctional programming in non-functional languages\n2.8\tData structures\n3\tComparison to imperative programming\n3.1\tSimulating state\n3.2\tEfficiency issues\n3.3\tCoding styles\n3.3.1\tPython\n3.3.2\tHaskell\n3.3.3\tPerl 6\n3.3.4\tErlang\n3.3.5\tElixir\n3.3.6\tLisp\n3.3.7\tClojure\n3.3.8\tD\n3.3.9\tR\n3.3.10\tSequenceL\n4\tUse in industry\n5\tIn education\n6\tSee also\n7\tReferences\n8\tFurther reading\n9\tExternal links\nHistory[edit]\nLambda calculus provides a theoretical framework for describing functions and their evaluation. Although it is a mathematical abstraction rather than a programming language, it forms the basis of almost all functional programming languages today. An equivalent theoretical formulation, combinatory logic, is commonly perceived as more abstract than lambda calculus and preceded it in invention. Combinatory logic and lambda calculus were both originally developed to achieve a clearer approach to the foundations of mathematics.[29]\n\nAn early functional-flavored language was Lisp, developed in the late 1950s for the IBM 700/7000 series scientific computers by John McCarthy while at Massachusetts Institute of Technology (MIT).[30] Lisp introduced many features now found in functional languages, though Lisp is technically a multi-paradigm language. Scheme and Dylan were later attempts to simplify and improve Lisp.\n\nInformation Processing Language (IPL) is sometimes cited as the first computer-based functional programming language.[31] It is an assembly-style language for manipulating lists of symbols. It does have a notion of \"generator\", which amounts to a function accepting a function as an argument, and, since it is an assembly-level language, code can be used as data, so IPL can be regarded as having higher-order functions. However, it relies heavily on mutating list structure and similar imperative features.\n\nKenneth E. Iverson developed APL in the early 1960s, described in his 1962 book A Programming Language (ISBN 9780471430148). APL was the primary influence on John Backus's FP. In the early 1990s, Iverson and Roger Hui created J. In the mid-1990s, Arthur Whitney, who had previously worked with Iverson, created K, which is used commercially in financial industries along with its descendant Q.\n\nJohn Backus presented FP in his 1977 Turing Award lecture \"Can Programming Be Liberated From the von Neumann Style? A Functional Style and its Algebra of Programs\".[32] He defines functional programs as being built up in a hierarchical way by means of \"combining forms\" that allow an \"algebra of programs\"; in modern language, this means that functional programs follow the principle of compositionality. Backus's paper popularized research into functional programming, though it emphasized function-level programming rather than the lambda-calculus style which has come to be associated with functional programming.\n\nIn the 1970s, ML was created by Robin Milner at the University of Edinburgh, and David Turner initially developed the language SASL at the University of St Andrews and later the language Miranda at the University of Kent. Also in Edinburgh in the 1970s, Burstall and Darlington developed the functional language NPL.[33] NPL was based on Kleene Recursion Equations and was first introduced in their work on program transformation.[34] Burstall, MacQueen and Sannella then incorporated the polymorphic type checking from ML to produce the language Hope.[35] ML eventually developed into several dialects, the most common of which are now OCaml and Standard ML. Meanwhile, the development of Scheme (a partly functional dialect of Lisp), as described in the influential Lambda Papers and the 1985 textbook Structure and Interpretation of Computer Programs, brought awareness of the power of functional programming to the wider programming-languages community.\n\nIn the 1980s, Per Martin-Löf developed intuitionistic type theory (also called constructive type theory), which associated functional programs with constructive proofs of arbitrarily complex mathematical propositions expressed as dependent types. This led to powerful new approaches to interactive theorem proving and has influenced the development of many subsequent functional programming languages.\n\nThe Haskell language began with a consensus in 1987 to form an open standard for functional programming research; implementation releases have been ongoing since 1990.\n\nConcepts[edit]\nA number of concepts and paradigms are specific to functional programming, and generally foreign to imperative programming (including object-oriented programming). However, programming languages are often hybrids of several programming paradigms, so programmers using \"mostly imperative\" languages may have utilized some of these concepts.[36]\n\nFirst-class and higher-order functions[edit]\nMain articles: First-class function and Higher-order function\nHigher-order functions are functions that can either take other functions as arguments or return them as results. In calculus, an example of a higher-order function is the differential operator {\\displaystyle d/dx} d/dx, which returns the derivative of a function {\\displaystyle f} f.\n\nHigher-order functions are closely related to first-class functions in that higher-order functions and first-class functions both allow functions as arguments and results of other functions. The distinction between the two is subtle: \"higher-order\" describes a mathematical concept of functions that operate on other functions, while \"first-class\" is a computer science term that describes programming language entities that have no restriction on their use (thus first-class functions can appear anywhere in the program that other first-class entities like numbers can, including as arguments to other functions and as their return values).\n\nHigher-order functions enable partial application or currying, a technique in which a function is applied to its arguments one at a time, with each application returning a new function that accepts the next argument. This allows one to succinctly express, for example, the successor function as the addition operator partially applied to the natural number one.\n\nPure functions[edit]\nPure functions (or expressions) have no side effects (memory or I/O). This means that pure functions have several useful properties, many of which can be used to optimize the code:\n\nIf the result of a pure expression is not used, it can be removed without affecting other expressions.\nIf a pure function is called with arguments that cause no side-effects, the result is constant with respect to that argument list (sometimes called referential transparency), i.e. if the pure function is again called with the same arguments, the same result will be returned (this can enable caching optimizations such as memoization).\nIf there is no data dependency between two pure expressions, then their order can be reversed, or they can be performed in parallel and they cannot interfere with one another (in other terms, the evaluation of any pure expression is thread-safe).\nIf the entire language does not allow side-effects, then any evaluation strategy can be used; this gives the compiler freedom to reorder or combine the evaluation of expressions in a program (for example, using deforestation).\nWhile most compilers for imperative programming languages detect pure functions and perform common-subexpression elimination for pure function calls, they cannot always do this for pre-compiled libraries, which generally do not expose this information, thus preventing optimizations that involve those external functions. Some compilers, such as gcc, add extra keywords for a programmer to explicitly mark external functions as pure, to enable such optimizations. Fortran 95 also allows functions to be designated \"pure\".\n\nRecursion[edit]\nMain article: Recursion (computer science)\nIteration (looping) in functional languages is usually accomplished via recursion. Recursive functions invoke themselves, allowing an operation to be performed over and over until the base case is reached. Though some recursion requires maintaining a stack, tail recursion can be recognized and optimized by a compiler into the same code used to implement iteration in imperative languages. The Scheme language standard requires implementations to recognize and optimize tail recursion. Tail recursion optimization can be implemented by transforming the program into continuation passing style during compiling, among other approaches.\n\nCommon patterns of recursion can be factored out using higher order functions, with catamorphisms and anamorphisms (or \"folds\" and \"unfolds\") being the most obvious examples. Such higher order functions play a role analogous to built-in control structures such as loops in imperative languages.\n\nMost general purpose functional programming languages allow unrestricted recursion and are Turing complete, which makes the halting problem undecidable, can cause unsoundness of equational reasoning, and generally requires the introduction of inconsistency into the logic expressed by the language's type system. Some special purpose languages such as Coq allow only well-founded recursion and are strongly normalizing (nonterminating computations can be expressed only with infinite streams of values called codata). As a consequence, these languages fail to be Turing complete and expressing certain functions in them is impossible, but they can still express a wide class of interesting computations while avoiding the problems introduced by unrestricted recursion. Functional programming limited to well-founded recursion with a few other constraints is called total functional programming.[37]\n\nStrict versus non-strict evaluation[edit]\nMain article: Evaluation strategy\nFunctional languages can be categorized by whether they use strict (eager) or non-strict (lazy) evaluation, concepts that refer to how function arguments are processed when an expression is being evaluated. The technical difference is in the denotational semantics of expressions containing failing or divergent computations. Under strict evaluation, the evaluation of any term containing a failing subterm will itself fail. For example, the expression:\n\nprint length([2+1, 3*2, 1/0, 5-4])\nwill fail under strict evaluation because of the division by zero in the third element of the list. Under lazy evaluation, the length function will return the value 4 (i.e., the number of items in the list), since evaluating it will not attempt to evaluate the terms making up the list. In brief, strict evaluation always fully evaluates function arguments before invoking the function. Lazy evaluation does not evaluate function arguments unless their values are required to evaluate the function call itself.\n\nThe usual implementation strategy for lazy evaluation in functional languages is graph reduction.[38] Lazy evaluation is used by default in several pure functional languages, including Miranda, Clean, and Haskell.\n\nHughes 1984 argues for lazy evaluation as a mechanism for improving program modularity through separation of concerns, by easing independent implementation of producers and consumers of data streams.[39] Launchbury 1993 describes some difficulties that lazy evaluation introduces, particularly in analyzing a program's storage requirements, and proposes an operational semantics to aid in such analysis.[40] Harper 2009 proposes including both strict and lazy evaluation in the same language, using the language's type system to distinguish them.[41]\n\nType systems[edit]\nEspecially since the development of Hindley–Milner type inference in the 1970s, functional programming languages have tended to use typed lambda calculus, rejecting all invalid programs at compilation time and risking false positive errors, as opposed to the untyped lambda calculus, that accepts all valid programs at compilation time and risks false negative errors, used in Lisp and its variants (such as Scheme), although they reject all invalid programs at runtime, when the information is enough to not reject valid programs. The use of algebraic datatypes makes manipulation of complex data structures convenient; the presence of strong compile-time type checking makes programs more reliable in absence of other reliability techniques like test-driven development, while type inference frees the programmer from the need to manually declare types to the compiler in most cases.\n\nSome research-oriented functional languages such as Coq, Agda, Cayenne, and Epigram are based on intuitionistic type theory, which allows types to depend on terms. Such types are called dependent types. These type systems do not have decidable type inference and are difficult to understand and program with[citation needed]. But dependent types can express arbitrary propositions in predicate logic. Through the Curry–Howard isomorphism, then, well-typed programs in these languages become a means of writing formal mathematical proofs from which a compiler can generate certified code. While these languages are mainly of interest in academic research (including in formalized mathematics), they have begun to be used in engineering as well. Compcert is a compiler for a subset of the C programming language that is written in Coq and formally verified.[42]\n\nA limited form of dependent types called generalized algebraic data types (GADT's) can be implemented in a way that provides some of the benefits of dependently typed programming while avoiding most of its inconvenience.[43] GADT's are available in the Glasgow Haskell Compiler, in OCaml (since version 4.00) and in Scala (as \"case classes\"), and have been proposed as additions to other languages including Java and C#.[44]\n\nReferential transparency[edit]\nMain article: Referential transparency\nFunctional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent.[45]\n\nConsider C assignment statement x = x * 10, this changes the value assigned to the variable x. Let us say that the initial value of x was 1, then two consecutive evaluations of the variable x will yield 10 and 100 respectively. Clearly, replacing x = x * 10 with either 10 or 100 gives a program with different meaning, and so the expression is not referentially transparent. In fact, assignment statements are never referentially transparent.\n\nNow, consider another function such as int plusone(int x) {return x+1;} is transparent, as it will not implicitly change the input x and thus has no such side effects. Functional programs exclusively use this type of function and are therefore referentially transparent.\n\nFunctional programming in non-functional languages[edit]\nIt is possible to use a functional style of programming in languages that are not traditionally considered functional languages.[46] For example, both D and Fortran 95 explicitly support pure functions.[47]\n\nJavaScript, Lua[48] and Python had first class functions from their inception.[49] Amrit Prem added support to Python for \"lambda\", \"map\", \"reduce\", and \"filter\" in 1994, as well as closures in Python 2.2,[50] though Python 3 relegated \"reduce\" to the functools standard library module.[51] First-class functions have been introduced into other mainstream languages such as PHP 5.3, Visual Basic 9, C# 3.0, and C++11.[citation needed]\n\nIn Java, anonymous classes can sometimes be used to simulate closures;[52] however, anonymous classes are not always proper replacements to closures because they have more limited capabilities.[53] Java 8 supports lambda expressions as a replacement for some anonymous classes.[54] However, the presence of checked exceptions in Java can make functional programming inconvenient, because it can be necessary to catch checked exceptions and then rethrow them—a problem that does not occur in other JVM languages that do not have checked exceptions, such as Scala.[citation needed]\n\nIn C#, anonymous classes are not necessary, because closures and lambdas are fully supported. Libraries and language extensions for immutable data structures are being developed to aid programming in the functional style in C#.\n\nMany object-oriented design patterns are expressible in functional programming terms: for example, the strategy pattern simply dictates use of a higher-order function, and the visitor pattern roughly corresponds to a catamorphism, or fold.\n\nSimilarly, the idea of immutable data from functional programming is often included in imperative programming languages,[55] for example the tuple in Python, which is an immutable array.\n\nData structures[edit]\nMain article: Purely functional data structure\nPurely functional data structures are often represented in a different way than their imperative counterparts.[56] For example, array with constant-time access and update is a basic component of most imperative languages and many imperative data-structure, such as hash table and binary heap, are based on arrays. Arrays can be replaced by map or random access list, which admits purely functional implementation, but the access and update time is logarithmic. Therefore, purely functional data structures can be used in languages which are non-functional, but they may not be the most efficient tool available, especially if persistency is not required.\n\nComparison to imperative programming[edit]\nFunctional programming is very different from imperative programming. The most significant differences stem from the fact that functional programming avoids side effects, which are used in imperative programming to implement state and I/O. Pure functional programming completely prevents side-effects and provides referential transparency.\n\nHigher-order functions are rarely used in older imperative programming. A traditional imperative program might use a loop to traverse and modify a list. A functional program, on the other hand, would probably use a higher-order “map” function that takes a function and a list, generating and returning a new list by applying the function to each list item.\n\nSimulating state[edit]\nThere are tasks (for example, maintaining a bank account balance) that often seem most naturally implemented with state. Pure functional programming performs these tasks, and I/O tasks such as accepting user input and printing to the screen, in a different way.\n\nThe pure functional programming language Haskell implements them using monads, derived from category theory. Monads offer a way to abstract certain types of computational patterns, including (but not limited to) modeling of computations with mutable state (and other side effects such as I/O) in an imperative manner without losing purity. While existing monads may be easy to apply in a program, given appropriate templates and examples, many students find them difficult to understand conceptually, e.g., when asked to define new monads (which is sometimes needed for certain types of libraries).[57]\n\nAnother way in which functional languages can simulate state is by passing around a data structure that represents the current state as a parameter to function calls. On each function call, a copy of this data structure is created with whatever differences are the result of the function. This is referred to as 'state-passing style'.\n\nImpure functional languages usually include a more direct method of managing mutable state. Clojure, for example, uses managed references that can be updated by applying pure functions to the current state. This kind of approach enables mutability while still promoting the use of pure functions as the preferred way to express computations.\n\nAlternative methods such as Hoare logic and uniqueness have been developed to track side effects in programs. Some modern research languages use effect systems to make the presence of side effects explicit.\n\nEfficiency issues[edit]\nFunctional programming languages are typically less efficient in their use of CPU and memory than imperative languages such as C and Pascal.[58] This is related to the fact that some mutable data structures like arrays have a very straightforward implementation using present hardware (which is a highly evolved Turing machine). Flat arrays may be accessed very efficiently with deeply pipelined CPUs, prefetched efficiently through caches (with no complex pointer chasing), or handled with SIMD instructions. It is also not easy to create their equally efficient general-purpose immutable counterparts. For purely functional languages, the worst-case slowdown is logarithmic in the number of memory cells used, because mutable memory can be represented by a purely functional data structure with logarithmic access time (such as a balanced tree).[59] However, such slowdowns are not universal. For programs that perform intensive numerical computations, functional languages such as OCaml and Clean are only slightly slower than C.[60] For programs that handle large matrices and multidimensional databases, array functional languages (such as J and K) were designed with speed optimizations.\n\nImmutability of data can in many cases lead to execution efficiency by allowing the compiler to make assumptions that are unsafe in an imperative language, thus increasing opportunities for inline expansion.[61]\n\nLazy evaluation may also speed up the program, even asymptotically, whereas it may slow it down at most by a constant factor (however, it may introduce memory leaks if used improperly). Launchbury 1993[40] discusses theoretical issues related to memory leaks from lazy evaluation, and O'Sullivan et al. 2008[62] give some practical advice for analyzing and fixing them. However, the most general implementations of lazy evaluation making extensive use of dereferenced code and data perform poorly on modern processors with deep pipelines and multi-level caches (where a cache miss may cost hundreds of cycles)[citation needed].\n\nCoding styles[edit]\n\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (July 2013) (Learn how and when to remove this template message)\nImperative programs have the environment and a sequence of steps manipulating the environment. Functional programs have an expression that is successively substituted until it reaches normal form. An example illustrates this with different solutions to the same programming goal (calculating Fibonacci numbers).\n\nPython[edit]\nPrinting first 10 Fibonacci numbers, iterative\n\ndef fibonacci(n, first=0, second=1):\n    while n != 0:\n        print(first, end=\"\\n\") # side-effect\n        n, first, second = n - 1, second, first + second # assignment\nfibonacci(10)\nPrinting first 10 Fibonacci numbers, functional expression style\n\nfibonacci = (lambda n, first=0, second=1:\n    \"\" if n == 0 else\n    str(first) + \"\\n\" + fibonacci(n - 1, second, first + second))\nprint(fibonacci(10), end=\"\")\nPrinting a list with first 10 Fibonacci numbers, with generators\n\ndef fibonacci(n, first=0, second=1):\n    while n != 0:\n        yield first\n        n, first, second = n - 1, second, first + second # assignment\nprint(list(fibonacci(10)))\nPrinting a list with first 10 Fibonacci numbers, functional expression style\n\nfibonacci = (lambda n, first=0, second=1:\n    [] if n == 0 else\n    [first] + fibonacci(n - 1, second, first + second))\nprint(fibonacci(10))\nHaskell[edit]\nPrinting first 10 fibonacci numbers, functional expression style[1]\n\nfibonacci_aux = \\n first second->\n    if n == 0 then \"\" else\n    show first ++ \"\\n\" ++ fibonacci_aux (n - 1) second (first + second)\nfibonacci = \\n-> fibonacci_aux n 0 1\nmain = putStr (fibonacci 10)\nPrinting a list with first 10 fibonacci numbers, functional expression style[1]\n\nfibonacci_aux = \\n first second->\n    if n == 0 then [] else\n    [first] ++ fibonacci_aux (n - 1) second (first + second)\nfibonacci = \\n-> fibonacci_aux n 0 1\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional expression style[1]\n\nfibonacci = \\n-> if n == 0 then 0\n                 else if n == 1 then 1\n                      else fibonacci(n - 1) + fibonacci(n - 2)\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional expression style,[1] tail recursive\n\nfibonacci_aux = \\n first second->\n    if n == 0 then first else\n    fibonacci_aux (n - 1) second (first + second)\nfibonacci = \\n-> fibonacci_aux n 0 1\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional expression style[1] with recursive lists\n\nfibonacci_aux = \\first second-> first : fibonacci_aux second (first + second)\nselect = \\n zs-> if n==0 then head zs\n                 else select (n - 1) (tail zs)\nfibonacci = \\n-> select n (fibonacci_aux 0 1)\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional expression style[1] with primitives for recursive lists\n\nfibonacci_aux = \\first second-> first : fibonacci_aux second (first + second)\nfibonacci = \\n-> (fibonacci_aux 0 1) !! n\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional expression style[1] with primitives for recursive lists, more concisely\n\nfibonacci_aux = 0:1:zipWith (+) fibonacci_aux (tail fibonacci_aux)\nfibonacci = \\n-> fibonacci_aux !! n\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional declaration style,[2] tail recursive\n\nfibonacci_aux 0 first _ = first\nfibonacci_aux n first second = fibonacci_aux (n - 1) second (first + second)\nfibonacci n = fibonacci_aux n 0 1\nmain = putStrLn (show (fibonacci 10))\nPrinting the 11th fibonacci number, functional declaration style, using lazy infinite lists and primitives\n\nfibs = 1 : 1 : zipWith (+) fibs (tail fibs) \n-- an infinite list of the fibonacci numbers\n-- fibs is defined in terms of fibs\nfibonacci = (fibs !!)\nmain = putStrLn $ show $ fibonacci 11\nPerl 6[edit]\nAs influenced by Haskell and others, Perl 6 has several functional and declarative approaches to problems. For example, you can declaratively build up a well-typed recursive version (the type constraints are optional) through signature pattern matching:\n\nsubset NonNegativeInt of Int where * >= 0;\n\nproto fib (|) is cached returns NonNegativeInt {*}\nmulti fib (0) { 0 }\nmulti fib (1) { 1 }\nmulti fib (NonNegativeInt $n) { fib($n - 1) + fib($n - 2) }\n\nfor ^10 -> $n { say fib($n) }\nAn alternative to this is to construct a lazy iterative sequence, which appears as an almost direct illustration of the sequence:\n\nmy @fib = 0, 1, *+* ... *; # Each additional entry is the sum of the previous two\n                           # and this sequence extends lazily indefinitely\nsay @fib[^10];             # Display the first 10 entries\nErlang[edit]\nErlang is a functional, concurrent, general-purpose programming language. A Fibonacci algorithm implemented in Erlang (Note: This is only for demonstrating the Erlang syntax. Use other algorithms for fast performance[63]):\n\n-module(fib).    % This is the file 'fib.erl', the module and the filename must match\n-export([fib/1]). % This exports the function 'fib' of arity 1\n\nfib(1) -> 1; % If 1, then return 1, otherwise (note the semicolon ; meaning 'else')\nfib(2) -> 1; % If 2, then return 1, otherwise\nfib(N) -> fib(N - 2) + fib(N - 1).\nElixir[edit]\nElixir is a functional, concurrent, general-purpose programming language that runs on the Erlang virtual machine (BEAM).\n\nThe Fibonacci function can be written in Elixir as follows:\n\ndefmodule Fibonacci do\n   def fib(0), do: 0\n   def fib(1), do: 1\n   def fib(n), do: fib(n-1) + fib(n-2)\nend\nLisp[edit]\nThe Fibonacci function can be written in Common Lisp as follows:\n\n(defun fib (n &optional (a 0) (b 1))\n  (if (= n 0)\n      a\n      (fib (- n 1) b (+ a b))))\nThe program can then be called as\n\n(fib 10)\nClojure[edit]\nThe Fibonacci function can be written in Clojure as follows:\n\n(defn fib\n  [n]\n  (loop [a 0 b 1 i n]\n    (if (zero? i)\n      a\n      (recur b (+ a b) (dec i)))))\nThe program can then be called as\n\n(fib 7)\nD[edit]\nD has support for functional programming[clarification needed][citation needed]:\n\nimport std.stdio;\nimport std.range;\n\nvoid main()\n{\n    /* 'f' is a range representing the first 10 Fibonacci numbers */\n    auto f = recurrence!((seq, i) => seq[0] + seq[1])(0, 1)\n             .take(10);\n\n    writeln(f);\n}\nR[edit]\nR is an environment for statistical computing and graphics. It is also a functional programming language.\n\nThe Fibonacci function can be written in R as a recursive function as follows:\n\nfib <- function(n) {\n if (n <= 2) 1\n else fib(n - 1) + fib(n - 2)\n}\nOr it can be written as a singly recursive function:\n\nfib <- function(n,a=1,b=1) { \n if (n == 1) a \n else fib(n-1,b,a+b) \n}\nOr it can be written as an iterative function:\n\nfib <- function(n) {\n if (n == 1) 1\n else if (n == 2) 1\n else {\n  fib<-c(1,1)\n  for (i in 3:n) fib<-c(0,fib[1])+fib[2]\n  fib[2]\n }\n}\nThe function can then be called as\n\nfib(10)\nSequenceL[edit]\nSequenceL is a functional, concurrent, general-purpose programming language. The Fibonacci function can be written in SequenceL as follows:\n\nfib(n) := n when n < 2 else\n          fib(n - 1) + fib(n - 2);\nThe function can then be called as\n\nfib(10)\nTo reduce the memory consumed by the call stack when computing a large Fibonacci term, a tail-recursive version can be used. A tail-recursive function is implemented by the SequenceL compiler as a memory-efficient looping structure:\n\nfib(n) := fib_Helper(0, 1, n);\n\nfib_Helper(prev, next, n) :=\n    prev when n < 1 else\n    next when n = 1 else\n    fib_Helper(next, next + prev, n - 1);\nUse in industry[edit]\nFunctional programming has long been popular in academia, but with few industrial applications.[64]:page 11 However, recently several prominent functional programming languages have been used in commercial or industrial systems. For example, the Erlang programming language, which was developed by the Swedish company Ericsson in the late 1980s, was originally used to implement fault-tolerant telecommunications systems.[13] It has since become popular for building a range of applications at companies such as T-Mobile, Nortel, Facebook, Électricité de France and WhatsApp.[12][14][65][66][67] The Scheme dialect of Lisp was used as the basis for several applications on early Apple Macintosh computers,[4][5] and has more recently been applied to problems such as training simulation software[6] and telescope control.[7] OCaml, which was introduced in the mid-1990s, has seen commercial use in areas such as financial analysis,[15] driver verification, industrial robot programming, and static analysis of embedded software.[16] Haskell, although initially intended as a research language,[18] has also been applied by a range of companies, in areas such as aerospace systems, hardware design, and web programming.[17][18]\n\nOther functional programming languages that have seen use in industry include Scala,[68] F#,[19][20] (both being functional-OO hybrids with support for both purely functional and imperative programming) Wolfram Language,[10] Lisp,[69] Standard ML[70][71] and Clojure[72]",
          "subparadigms": [
            15
          ]
        },
        {
          "pdid": 21,
          "name": "Logic programming",
          "details": "Logic programming is a programming paradigm based on formal logic. A program written in a logic programming language is a set of sentences in logical form, expressing facts and rules about some problem domain. Major logic programming language families include Prolog, Answer set programming (ASP) and Datalog. In all of these languages, rules are written in the form of clauses:\n\nH :- B1, …, Bn.\nand are read declaratively as logical implications:\n\nH if B1 and … and Bn.\nH is called the head of the rule and B1, …, Bn is called the body. Facts are rules that have no body, and are written in the simplified form:\n\nH.\nIn the simplest case in which H, B1, …, Bn are all atomic formulae, these clauses are called definite clauses or Horn clauses. However, there exist many extensions of this simple case, the most important one being the case in which conditions in the body of a clause can also be negations of atomic formulae. Logic programming languages that include this extension have the knowledge representation capabilities of a non-monotonic logic.\n\nIn ASP and Datalog, logic programs have only a declarative reading, and their execution is performed by means of a proof procedure or model generator whose behaviour is not meant to be under the control of the programmer. However, in the Prolog family of languages, logic programs also have a procedural interpretation as goal-reduction procedures:\n\nto solve H, solve B1, and ... and solve Bn.\nConsider, for example, the following clause:\n\nfallible(X) :- human(X).\nbased on an example used by Terry Winograd [1] to illustrate the programming language Planner. As a clause in a logic program, it can be used both as a procedure to test whether X is fallible by testing whether X is human, and as a procedure to find an X that is fallible by finding an X that is human. Even facts have a procedural interpretation. For example, the clause:\n\nhuman(socrates).\ncan be used both as a procedure to show that socrates is human, and as a procedure to find an X that is human by \"assigning\" socrates to X.\n\nThe declarative reading of logic programs can be used by a programmer to verify their correctness. Moreover, logic-based program transformation techniques can also be used to transform logic programs into logically equivalent programs that are more efficient. In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs.",
          "subparadigms": [
            16
          ]
        },
        {
          "pdid": 22,
          "name": "Declarative programming",
          "details": "In computer science, declarative programming is a programming paradigm—a style of building the structure and elements of computer programs—that expresses the logic of a computation without describing its control flow.[1]\n\nMany languages that apply this style attempt to minimize or eliminate side effects by describing what the program must accomplish in terms of the problem domain, rather than describe how to accomplish it as a sequence of the programming language primitives[2] (the how being left up to the language's implementation). This is in contrast with imperative programming, which implements algorithms in explicit steps.\n\nDeclarative programming often considers programs as theories of a formal logic, and computations as deductions in that logic space. Declarative programming may greatly simplify writing parallel programs.[3]\n\nCommon declarative languages include those of database query languages (e.g., SQL, XQuery), regular expressions, logic programming, functional programming, and configuration management systems.",
          "subparadigms": [
            16,
            21
          ]
        },
        {
          "pdid": 33,
          "name": "Procedural",
          "details": "Procedural programming is a programming paradigm, derived from structured programming, based upon the concept of the procedure call. Procedures, also known as routines, subroutines, or functions (not to be confused with mathematical functions, but similar to those used in functional programming), simply contain a series of computational steps to be carried out. Any given procedure might be called at any point during a program's execution, including by other procedures or itself. Procedural programming languages include C, Go, Fortran, Pascal, Ada, and BASIC.[1]\n\nComputer processors provide hardware support for procedural programming through a stack register and instructions for calling procedures and returning from them. Hardware support for other types of programming is possible, but no attempt was commercially successful (for example Lisp machines or Java processors).",
          "subparadigms": []
        },
        {
          "pdid": 34,
          "name": "Imperative",
          "details": "In computer science, imperative programming is a programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.\n\nThe term is often used in contrast to declarative programming, which focuses on what the program should accomplish without specifying how the program should achieve the result.",
          "subparadigms": [
            33
          ]
        },
        {
          "pdid": 43,
          "name": "Automatic",
          "details": "In computer science, the term automatic programming[1] identifies a type of computer programming in which some mechanism generates a computer program to allow human programmers to write the code at a higher abstraction level.\n\nThere has been little agreement on the precise definition of automatic programming, mostly because its meaning has changed over time. David Parnas, tracing the history of \"automatic programming\" in published research, noted that in the 1940s it described automation of the manual process of punching paper tape. Later it referred to translation of high-level programming languages like Fortran and ALGOL. In fact, one of the earliest programs identifiable as a compiler was called Autocode. Parnas concluded that \"automatic programming has always been a euphemism for programming in a higher-level language than was then available to the programmer.\"[2]\n\nProgram synthesis is one type of automatic programming where a procedure is created from scratch, based on mathematical requirements.",
          "subparadigms": []
        },
        {
          "pdid": 45,
          "name": "Reflection",
          "details": "In computer science, reflection is the ability of a computer program to examine, introspect, and modify its own structure and behavior at runtime",
          "subparadigms": []
        },
        {
          "pdid": 60,
          "name": "Prototype-based",
          "details": "Prototype-based programming is a style of object-oriented programming in which behaviour reuse (known as inheritance) is performed via a process of reusing existing objects via delegation that serve as prototypes. This model can also be known as prototypal, prototype-oriented, classless, or instance-based programming. Delegation is the language feature that supports prototype-based programming.\n\nA fruit bowl serves as one example. A \"fruit\" object would represent the properties and functionality of fruit in general. A \"banana\" object would be cloned from the \"fruit\" object, and would also be extended to include general properties specific to bananas. Each individual \"banana\" object would be cloned from the generic \"banana\" object.\n\nThe first prototype-oriented programming language was Self, developed by David Ungar and Randall Smith in the mid-1980s to research topics in object-oriented language design. Since the late 1990s, the classless paradigm has grown increasingly popular.[citation needed] Some current prototype-oriented languages are JavaScript (and other ECMAScript implementations, JScript and Flash's ActionScript 1.0), Lua, Cecil, NewtonScript, Io, Ioke, MOO, REBOL, Lisaac and AHk.",
          "subparadigms": []
        },
        {
          "pdid": 62,
          "name": "Class-based",
          "details": "Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance is achieved by defining classes of objects, as opposed to the objects themselves (compare prototype-based programming).\n\nThe most popular and developed model of OOP is a class-based model, as opposed to an object-based model. In this model, objects are entities that combine state (i.e. data), behavior (i.e. procedures, or methods) and identity (unique existence among all other objects). The structure and behavior of an object are defined by a class, which is a definition, or blueprint, of all objects of a specific type. An object must be explicitly created based on a class and an object thus created is considered to be an instance of that class. An object is similar to a structure, with the addition of method pointers, member access control, and an implicit data member which locates instances of the class (i.e. actual objects of that class) in the class hierarchy (essential for runtime inheritance features).",
          "subparadigms": []
        },
        {
          "pdid": 63,
          "name": "Actor-based",
          "details": "The actor model in computer science is a mathematical model of concurrent computation that treats \"actors\" as the universal primitives of concurrent computation. In response to a message that it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received. Actors may modify private state, but can only affect each other through messages (avoiding the need for any locks).\n\nThe actor model originated in 1973.[1] It has been used both as a framework for a theoretical understanding of computation and as the theoretical basis for several practical implementations of concurrent systems. The relationship of the model to other work is discussed in Indeterminacy in concurrent computation and Actor model and process calculi.",
          "subparadigms": []
        },
        {
          "pdid": 64,
          "name": "Object-oriented",
          "details": "Object-oriented programming (OOP) is a programming paradigm based on the concept of \"objects\", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated (objects have a notion of \"this\" or \"self\"). In OOP, computer programs are designed by making them out of objects that interact with one another.[1][2] There is significant diversity of OOP languages, but the most popular ones are class-based, meaning that objects are instances of classes, which typically also determine their type.\n\nMany of the most widely used programming languages are multi-paradigm programming languages that support object-oriented programming to a greater or lesser degree, typically in combination with imperative, procedural programming. Significant object-oriented languages include Java, C++, C#, Python, PHP, Ruby, Perl, Delphi, Objective-C, Swift, Common Lisp, and Smalltalk.\n\nContents  [hide] \n1\tFeatures\n1.1\tShared with non-OOP predecessor languages\n1.2\tObjects and classes\n1.3\tDynamic dispatch/message passing\n1.4\tEncapsulation\n1.5\tComposition, inheritance, and delegation\n1.6\tPolymorphism\n1.7\tOpen recursion\n2\tHistory\n3\tOOP languages\n3.1\tOOP in dynamic languages\n3.2\tOOP in a network protocol\n4\tDesign patterns\n4.1\tInheritance and behavioral subtyping\n4.2\tGang of Four design patterns\n4.3\tObject-orientation and databases\n4.4\tReal-world modeling and relationships\n4.5\tOOP and control flow\n4.6\tResponsibility- vs. data-driven design\n4.7\tSOLID and GRASP guidelines\n5\tCriticism\n6\tFormal semantics\n7\tSee also\n7.1\tSystems\n7.2\tModeling languages\n8\tReferences\n9\tFurther reading\n10\tExternal links\nFeatures[edit]\nObject-oriented Programming uses objects, but not all of the associated techniques and structures are supported directly in languages that claim to support OOP. The features listed below are, however, common among languages considered strongly class- and object-oriented (or multi-paradigm with OOP support), with notable exceptions mentioned.[3][4][5][6]\n\nSee also: Comparison of programming languages (object-oriented programming) and List of object-oriented programming terms\nShared with non-OOP predecessor languages[edit]\nObject-oriented programming languages typically share low-level features with high-level procedural programming languages (which were invented first). The fundamental tools that can be used to construct a program include:\n\nVariables that can store information formatted in a small number of built-in data types like integers and alphanumeric characters. This may include data structures like strings, lists, and hash tables that are either built-in or result from combining variables using memory pointers\nProcedures – also known as functions, methods, routines, or subroutines – that take input, generate output, and manipulate data. Modern languages include structured programming constructs like loops and conditionals.\nModular programming support provides the ability to group procedures into files and modules for organizational purposes. Modules are namespaced so code in one module will not be accidentally confused with the same procedure or variable name in another file or module.\n\nObjects and classes[edit]\nLanguages that support object-oriented programming typically use inheritance for code reuse and extensibility in the form of either classes or prototypes. Those that use classes support two main concepts:\n\nClasses – the definitions for the data format and available procedures for a given type or class of object; may also contain data and procedures (known as class methods) themselves, i.e. classes contains the data members and member functions\nObjects – instances of classes\nObjects sometimes correspond to things found in the real world. For example, a graphics program may have objects such as \"circle\", \"square\", \"menu\". An online shopping system might have objects such as \"shopping cart\", \"customer\", and \"product\".[7] Sometimes objects represent more abstract entities, like an object that represents an open file, or an object that provides the service of translating measurements from U.S. customary to metric.\n\nEach object is said to be an instance of a particular class (for example, an object with its name field set to \"Mary\" might be an instance of class Employee). Procedures in object-oriented programming are known as methods; variables are also known as fields, members, attributes, or properties. This leads to the following terms:\n\nClass variables – belong to the class as a whole; there is only one copy of each one\nInstance variables or attributes – data that belongs to individual objects; every object has its own copy of each one\nMember variables – refers to both the class and instance variables that are defined by a particular class\nClass methods – belong to the class as a whole and have access only to class variables and inputs from the procedure call\nInstance methods – belong to individual objects, and have access to instance variables for the specific object they are called on, inputs, and class variables\nObjects are accessed somewhat like variables with complex internal structure, and in many languages are effectively pointers, serving as actual references to a single instance of said object in memory within a heap or stack. They provide a layer of abstraction which can be used to separate internal from external code. External code can use an object by calling a specific instance method with a certain set of input parameters, read an instance variable, or write to an instance variable. Objects are created by calling a special type of method in the class known as a constructor. A program may create many instances of the same class as it runs, which operate independently. This is an easy way for the same procedures to be used on different sets of data.\n\nObject-oriented programming that uses classes is sometimes called class-based programming, while prototype-based programming does not typically use classes. As a result, a significantly different yet analogous terminology is used to define the concepts of object and instance.\n\nIn some languages classes and objects can be composed using other concepts like traits and mixins.\n\nDynamic dispatch/message passing[edit]\nIt is the responsibility of the object, not any external code, to select the procedural code to execute in response to a method call, typically by looking up the method at run time in a table associated with the object. This feature is known as dynamic dispatch, and distinguishes an object from an abstract data type (or module), which has a fixed (static) implementation of the operations for all instances. If there are multiple methods that might be run for a given name, it is known as multiple dispatch.\n\nA method call is also known as message passing. It is conceptualized as a message (the name of the method and its input parameters) being passed to the object for dispatch.\n\nEncapsulation[edit]\nEncapsulation is an Object Oriented Programming concept that binds together the data and functions that manipulate the data, and that keeps both safe from outside interference and misuse. Data encapsulation led to the important OOP concept of data hiding.\n\nIf a class does not allow calling code to access internal object data and permits access through methods only, this is a strong form of abstraction or information hiding known as encapsulation. Some languages (Java, for example) let classes enforce access restrictions explicitly, for example denoting internal data with the private keyword and designating methods intended for use by code outside the class with the public keyword. Methods may also be designed public, private, or intermediate levels such as protected (which allows access from the same class and its subclasses, but not objects of a different class). In other languages (like Python) this is enforced only by convention (for example, private methods may have names that start with an underscore). Encapsulation prevents external code from being concerned with the internal workings of an object. This facilitates code refactoring, for example allowing the author of the class to change how objects of that class represent their data internally without changing any external code (as long as \"public\" method calls work the same way). It also encourages programmers to put all the code that is concerned with a certain set of data in the same class, which organizes it for easy comprehension by other programmers. Encapsulation is a technique that encourages decoupling.\n\nComposition, inheritance, and delegation[edit]\nObjects can contain other objects in their instance variables; this is known as object composition. For example, an object in the Employee class might contain (point to) an object in the Address class, in addition to its own instance variables like \"first_name\" and \"position\". Object composition is used to represent \"has-a\" relationships: every employee has an address, so every Employee object has a place to store an Address object.\n\nLanguages that support classes almost always support inheritance. This allows classes to be arranged in a hierarchy that represents \"is-a-type-of\" relationships. For example, class Employee might inherit from class Person. All the data and methods available to the parent class also appear in the child class with the same names. For example, class Person might define variables \"first_name\" and \"last_name\" with method \"make_full_name()\". These will also be available in class Employee, which might add the variables \"position\" and \"salary\". This technique allows easy re-use of the same procedures and data definitions, in addition to potentially mirroring real-world relationships in an intuitive way. Rather than utilizing database tables and programming subroutines, the developer utilizes objects the user may be more familiar with: objects from their application domain.[8]\n\nSubclasses can override the methods defined by superclasses. Multiple inheritance is allowed in some languages, though this can make resolving overrides complicated. Some languages have special support for mixins, though in any language with multiple inheritance, a mixin is simply a class that does not represent an is-a-type-of relationship. Mixins are typically used to add the same methods to multiple classes. For example, class UnicodeConversionMixin might provide a method unicode_to_ascii() when included in class FileReader and class WebPageScraper, which don't share a common parent.\n\nAbstract classes cannot be instantiated into objects; they exist only for the purpose of inheritance into other \"concrete\" classes which can be instantiated. In Java, the final keyword can be used to prevent a class from being subclassed.\n\nThe doctrine of composition over inheritance advocates implementing has-a relationships using composition instead of inheritance. For example, instead of inheriting from class Person, class Employee could give each Employee object an internal Person object, which it then has the opportunity to hide from external code even if class Person has many public attributes or methods. Some languages, like Go do not support inheritance at all.\n\nThe \"open/closed principle\" advocates that classes and functions \"should be open for extension, but closed for modification\".\n\nDelegation is another language feature that can be used as an alternative to inheritance.\n\nPolymorphism[edit]\nSubtyping, a form of polymorphism, is when calling code can be agnostic as to whether an object belongs to a parent class or one of its descendants. For example, a function might call \"make_full_name()\" on an object, which will work whether the object is of class Person or class Employee. This is another type of abstraction which simplifies code external to the class hierarchy and enables strong separation of concerns.\n\nOpen recursion[edit]\nIn languages that support open recursion, object methods can call other methods on the same object (including themselves), typically using a special variable or keyword called this or self. This variable is late-bound; it allows a method defined in one class to invoke another method that is defined later, in some subclass thereof.\n\nHistory[edit]\nTerminology invoking \"objects\" and \"oriented\" in the modern sense of object-oriented programming made its first appearance at MIT in the late 1950s and early 1960s. In the environment of the artificial intelligence group, as early as 1960, \"object\" could refer to identified items (LISP atoms) with properties (attributes);[9][10] Alan Kay was later to cite a detailed understanding of LISP internals as a strong influence on his thinking in 1966.[11] Another early MIT example was Sketchpad created by Ivan Sutherland in 1960–61; in the glossary of the 1963 technical report based on his dissertation about Sketchpad, Sutherland defined notions of \"object\" and \"instance\" (with the class concept covered by \"master\" or \"definition\"), albeit specialized to graphical interaction.[12] Also, an MIT ALGOL version, AED-0, established a direct link between data structures (\"plexes\", in that dialect) and procedures, prefiguring what were later termed \"messages\", \"methods\", and \"member functions\".[13][14]\n\nThe formal programming concept of objects was introduced in the mid-1960s with Simula 67, a major revision of Simula I, a programming language designed for discrete event simulation, created by Ole-Johan Dahl and Kristen Nygaard of the Norwegian Computing Center in Oslo.[15][not in citation given][citation needed] [16][not in citation given][citation needed] [17] [18] [19]\n\nSimula 67 was influenced by SIMSCRIPT and C.A.R. \"Tony\" Hoare's proposed \"record classes\".[13][20] Simula introduced the notion of classes and instances or objects (as well as subclasses, virtual procedures, coroutines, and discrete event simulation) as part of an explicit programming paradigm. The language also used automatic garbage collection that had been invented earlier for the functional programming language Lisp. Simula was used for physical modeling, such as models to study and improve the movement of ships and their content through cargo ports. The ideas of Simula 67 influenced many later languages, including Smalltalk, derivatives of LISP (CLOS), Object Pascal, and C++.\n\nThe Smalltalk language, which was developed at Xerox PARC (by Alan Kay and others) in the 1970s, introduced the term object-oriented programming to represent the pervasive use of objects and messages as the basis for computation. Smalltalk creators were influenced by the ideas introduced in Simula 67, but Smalltalk was designed to be a fully dynamic system in which classes could be created and modified dynamically rather than statically as in Simula 67.[21] Smalltalk and with it OOP were introduced to a wider audience by the August 1981 issue of Byte Magazine.\n\nIn the 1970s, Kay's Smalltalk work had influenced the Lisp community to incorporate object-based techniques that were introduced to developers via the Lisp machine. Experimentation with various extensions to Lisp (such as LOOPS and Flavors introducing multiple inheritance and mixins) eventually led to the Common Lisp Object System, which integrates functional programming and object-oriented programming and allows extension via a Meta-object protocol. In the 1980s, there were a few attempts to design processor architectures that included hardware support for objects in memory but these were not successful. Examples include the Intel iAPX 432 and the Linn Smart Rekursiv.\n\nIn 1985, Bertrand Meyer produced the first design of the Eiffel language. Focused on software quality, Eiffel is among the purely object-oriented languages, but differs in the sense that the language itself is not only a programming language, but a notation supporting the entire software lifecycle. Meyer described the Eiffel software development method, based on a small number of key ideas from software engineering and computer science, in Object-Oriented Software Construction. Essential to the quality focus of Eiffel is Meyer's reliability mechanism, Design by Contract, which is an integral part of both the method and language.\n\nObject-oriented programming developed as the dominant programming methodology in the early and mid 1990s when programming languages supporting the techniques became widely available. These included Visual FoxPro 3.0,[22][23][24] C++,[25] and Delphi[citation needed]. Its dominance was further enhanced by the rising popularity of graphical user interfaces, which rely heavily upon object-oriented programming techniques. An example of a closely related dynamic GUI library and OOP language can be found in the Cocoa frameworks on Mac OS X, written in Objective-C, an object-oriented, dynamic messaging extension to C based on Smalltalk. OOP toolkits also enhanced the popularity of event-driven programming (although this concept is not limited to OOP).\n\nAt ETH Zürich, Niklaus Wirth and his colleagues had also been investigating such topics as data abstraction and modular programming (although this had been in common use in the 1960s or earlier). Modula-2 (1978) included both, and their succeeding design, Oberon, included a distinctive approach to object orientation, classes, and such.\n\nObject-oriented features have been added to many previously existing languages, including Ada, BASIC, Fortran, Pascal, and COBOL. Adding these features to languages that were not initially designed for them often led to problems with compatibility and maintainability of code.\n\nMore recently, a number of languages have emerged that are primarily object-oriented, but that are also compatible with procedural methodology. Two such languages are Python and Ruby. Probably the most commercially important recent object-oriented languages are Java, developed by Sun Microsystems, as well as C# and Visual Basic.NET (VB.NET), both designed for Microsoft's .NET platform. Each of these two frameworks shows, in its own way, the benefit of using OOP by creating an abstraction from implementation. VB.NET and C# support cross-language inheritance, allowing classes defined in one language to subclass classes defined in the other language.\n\nOOP languages[edit]\n\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (August 2009) (Learn how and when to remove this template message)\nSee also: List of object-oriented programming languages\nSimula (1967) is generally accepted as being the first language with the primary features of an object-oriented language. It was created for making simulation programs, in which what came to be called objects were the most important information representation. Smalltalk (1972 to 1980) is another early example, and the one with which much of the theory of OOP was developed. Concerning the degree of object orientation, the following distinctions can be made:\n\nLanguages called \"pure\" OO languages, because everything in them is treated consistently as an object, from primitives such as characters and punctuation, all the way up to whole classes, prototypes, blocks, modules, etc. They were designed specifically to facilitate, even enforce, OO methods. Examples: Python, Ruby, Scala, Smalltalk, Eiffel, Emerald,[26] JADE, Self.\nLanguages designed mainly for OO programming, but with some procedural elements. Examples: Java, C++, C#, Delphi/Object Pascal, VB.NET.\nLanguages that are historically procedural languages, but have been extended with some OO features. Examples: PHP, Perl, Visual Basic (derived from BASIC), MATLAB, COBOL 2002, Fortran 2003, ABAP, Ada 95, Pascal.\nLanguages with most of the features of objects (classes, methods, inheritance), but in a distinctly original form. Examples: Oberon (Oberon-1 or Oberon-2).\nLanguages with abstract data type support which may be used to resemble OO programming, but without all features of object-orientation. This includes object-based and prototype-based languages. Examples: JavaScript, Lua, Modula-2, CLU.\nChameleon languages that support multiple paradigms, including OO. Tcl stands out among these for TclOO, a hybrid object system that supports both prototype-based programming and class-based OO.\nOOP in dynamic languages[edit]\nIn recent years, object-oriented programming has become especially popular in dynamic programming languages. Python, PowerShell, Ruby and Groovy are dynamic languages built on OOP principles, while Perl and PHP have been adding object-oriented features since Perl 5 and PHP 4, and ColdFusion since version 6.\n\nThe Document Object Model of HTML, XHTML, and XML documents on the Internet has bindings to the popular JavaScript/ECMAScript language. JavaScript is perhaps the best known prototype-based programming language, which employs cloning from prototypes rather than inheriting from a class (contrast to class-based programming). Another scripting language that takes this approach is Lua.\n\nOOP in a network protocol[edit]\nThe messages that flow between computers to request services in a client-server environment can be designed as the linearizations of objects defined by class objects known to both the client and the server. For example, a simple linearized object would consist of a length field, a code point identifying the class, and a data value. A more complex example would be a command consisting of the length and code point of the command and values consisting of linearized objects representing the command's parameters. Each such command must be directed by the server to an object whose class (or superclass) recognizes the command and is able to provide the requested service. Clients and servers are best modeled as complex object-oriented structures. Distributed Data Management Architecture (DDM) took this approach and used class objects to define objects at four levels of a formal hierarchy:\n\nFields defining the data values that form messages, such as their length, codepoint and data values.\nObjects and collections of objects similar to what would be found in a Smalltalk program for messages and parameters.\nManagers similar to AS/400 objects, such as a directory to files and files consisting of metadata and records. Managers conceptually provide memory and processing resources for their contained objects.\nA client or server consisting of all the managers necessary to implement a full processing environment, supporting such aspects as directory services, security and concurrency control.\nThe initial version of DDM defined distributed file services. It was later extended to be the foundation of Distributed Relational Database Architecture (DRDA).\n\nDesign patterns[edit]\nChallenges of object-oriented design are addressed by several methodologies. Most common is known as the design patterns codified by Gamma et al.. More broadly, the term \"design patterns\" can be used to refer to any general, repeatable solution to a commonly occurring problem in software design. Some of these commonly occurring problems have implications and solutions particular to object-oriented development.\n\nInheritance and behavioral subtyping[edit]\nSee also: Object-oriented design\nIt is intuitive to assume that inheritance creates a semantic \"is a\" relationship, and thus to infer that objects instantiated from subclasses can always be safely used instead of those instantiated from the superclass. This intuition is unfortunately false in most OOP languages, in particular in all those that allow mutable objects. Subtype polymorphism as enforced by the type checker in OOP languages (with mutable objects) cannot guarantee behavioral subtyping in any context. Behavioral subtyping is undecidable in general, so it cannot be implemented by a program (compiler). Class or object hierarchies must be carefully designed, considering possible incorrect uses that cannot be detected syntactically. This issue is known as the Liskov substitution principle.\n\nGang of Four design patterns[edit]\nMain article: Design pattern (computer science)\nDesign Patterns: Elements of Reusable Object-Oriented Software is an influential book published in 1995 by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, often referred to humorously as the \"Gang of Four\". Along with exploring the capabilities and pitfalls of object-oriented programming, it describes 23 common programming problems and patterns for solving them. As of April 2007, the book was in its 36th printing.\n\nThe book describes the following patterns:\n\nCreational patterns (5): Factory method pattern, Abstract factory pattern, Singleton pattern, Builder pattern, Prototype pattern\nStructural patterns (7): Adapter pattern, Bridge pattern, Composite pattern, Decorator pattern, Facade pattern, Flyweight pattern, Proxy pattern\nBehavioral patterns (11): Chain-of-responsibility pattern, Command pattern, Interpreter pattern, Iterator pattern, Mediator pattern, Memento pattern, Observer pattern, State pattern, Strategy pattern, Template method pattern, Visitor pattern\nObject-orientation and databases[edit]\nMain articles: Object-relational impedance mismatch, Object-relational mapping, and Object database\nBoth object-oriented programming and relational database management systems (RDBMSs) are extremely common in software today. Since relational databases don't store objects directly (though some RDBMSs have object-oriented features to approximate this), there is a general need to bridge the two worlds. The problem of bridging object-oriented programming accesses and data patterns with relational databases is known as object-relational impedance mismatch. There are a number of approaches to cope with this problem, but no general solution without downsides.[27] One of the most common approaches is object-relational mapping, as found in IDE languages such as Visual FoxPro and libraries such as Java Data Objects and Ruby on Rails' ActiveRecord.\n\nThere are also object databases that can be used to replace RDBMSs, but these have not been as technically and commercially successful as RDBMSs.\n\nReal-world modeling and relationships[edit]\nOOP can be used to associate real-world objects and processes with digital counterparts. However, not everyone agrees that OOP facilitates direct real-world mapping (see Criticism section) or that real-world mapping is even a worthy goal; Bertrand Meyer argues in Object-Oriented Software Construction[28] that a program is not a model of the world but a model of some part of the world; \"Reality is a cousin twice removed\". At the same time, some principal limitations of OOP had been noted.[29] For example, the circle-ellipse problem is difficult to handle using OOP's concept of inheritance.\n\nHowever, Niklaus Wirth (who popularized the adage now known as Wirth's law: \"Software is getting slower more rapidly than hardware becomes faster\") said of OOP in his paper, \"Good Ideas through the Looking Glass\", \"This paradigm closely reflects the structure of systems 'in the real world', and it is therefore well suited to model complex systems with complex behaviours\"[30] (contrast KISS principle).\n\nSteve Yegge and others noted that natural languages lack the OOP approach of strictly prioritizing things (objects/nouns) before actions (methods/verbs).[31] This problem may cause OOP to suffer more convoluted solutions than procedural programming.[32]\n\nOOP and control flow[edit]\nOOP was developed to increase the reusability and maintainability of source code.[33] Transparent representation of the control flow had no priority and was meant to be handled by a compiler. With the increasing relevance of parallel hardware and multithreaded coding, developing transparent control flow becomes more important, something hard to achieve with OOP.[34][35][36][37]\n\nResponsibility- vs. data-driven design[edit]\nResponsibility-driven design defines classes in terms of a contract, that is, a class should be defined around a responsibility and the information that it shares. This is contrasted by Wirfs-Brock and Wilkerson with data-driven design, where classes are defined around the data-structures that must be held. The authors hold that responsibility-driven design is preferable.\n\nSOLID and GRASP guidelines[edit]\nSOLID is a mnemonic invented by Michael Feathers that stands for and advocates five programming practices:\n\nSingle responsibility principle\nOpen/closed principle\nLiskov substitution principle\nInterface segregation principle\nDependency inversion principle\nGRASP (General Responsibility Assignment Software Patterns) is another set of guidelines advocated by Craig Larman.\n\nCriticism[edit]\nThe OOP paradigm has been criticised for a number of reasons, including not meeting its stated goals of reusability and modularity,[38][39] and for overemphasizing one aspect of software design and modeling (data/objects) at the expense of other important aspects (computation/algorithms).[40][41]\n\nLuca Cardelli has claimed that OOP code is \"intrinsically less efficient\" than procedural code, that OOP can take longer to compile, and that OOP languages have \"extremely poor modularity properties with respect to class extension and modification\", and tend to be extremely complex.[38] The latter point is reiterated by Joe Armstrong, the principal inventor of Erlang, who is quoted as saying:[39]\n\nThe problem with object-oriented languages is they've got all this implicit environment that they carry around with them. You wanted a banana but what you got was a gorilla holding the banana and the entire jungle.\n\nA study by Potok et al. has shown no significant difference in productivity between OOP and procedural approaches.[42]\n\nChristopher J. Date stated that critical comparison of OOP to other technologies, relational in particular, is difficult because of lack of an agreed-upon and rigorous definition of OOP;[43] however, Date and Darwen have proposed a theoretical foundation on OOP that uses OOP as a kind of customizable type system to support RDBMS.[44]\n\nIn an article Lawrence Krubner claimed that compared to other languages (LISP dialects, functional languages, etc.) OOP languages have no unique strengths, and inflict a heavy burden of unneeded complexity.[45]\n\nAlexander Stepanov compares object orientation unfavourably to generic programming:[40]\n\nI find OOP technically unsound. It attempts to decompose the world in terms of interfaces that vary on a single type. To deal with the real problems you need multisorted algebras — families of interfaces that span multiple types. I find OOP philosophically unsound. It claims that everything is an object. Even if it is true it is not very interesting — saying that everything is an object is saying nothing at all.\n\nPaul Graham has suggested that OOP's popularity within large companies is due to \"large (and frequently changing) groups of mediocre programmers\". According to Graham, the discipline imposed by OOP prevents any one programmer from \"doing too much damage\".[46]\n\nSteve Yegge noted that, as opposed to functional programming:[47]\n\nObject Oriented Programming puts the Nouns first and foremost. Why would you go to such lengths to put one part of speech on a pedestal? Why should one kind of concept take precedence over another? It's not as if OOP has suddenly made verbs less important in the way we actually think. It's a strangely skewed perspective.\n\nRich Hickey, creator of Clojure, described object systems as overly simplistic models of the real world. He emphasized the inability of OOP to model time properly, which is getting increasingly problematic as software systems become more concurrent.[41]\n\nEric S. Raymond, a Unix programmer and open-source software advocate, has been critical of claims that present object-oriented programming as the \"One True Solution\", and has written that object-oriented programming languages tend to encourage thickly layered programs that destroy transparency.[48] Raymond compares this unfavourably to the approach taken with Unix and the C programming language.[48]\n\nRob Pike, a programmer involved in the creation of UTF-8 and Go, has called the design of object-oriented programming \"the Roman numerals of computing\"[49] and has said that OOP languages frequently shift the focus from data structures and algorithms to types.[50] Furthermore, he cites an instance of a Java professor whose \"idiomatic\" solution to a problem was to create six new classes, rather than to simply use a lookup table.[51]\n\nFormal semantics[edit]\nSee also: Formal semantics of programming languages\nObjects are the run-time entities in an object-oriented system. They may represent a person, a place, a bank account, a table of data, or any item that the program has to handle.\n\nThere have been several attempts at formalizing the concepts used in object-oriented programming. The following concepts and constructs have been used as interpretations of OOP concepts:\n\nco algebraic data types[52]\nabstract data types (which have existential types) allow the definition of modules but these do not support dynamic dispatch\nrecursive types\nencapsulated state\ninheritance\nrecords are basis for understanding objects if function literals can be stored in fields (like in functional programming languages), but the actual calculi need be considerably more complex to incorporate essential features of OOP. Several extensions of System F<: that deal with mutable objects have been studied;[53] these allow both subtype polymorphism and parametric polymorphism (generics)\nAttempts to find a consensus definition or theory behind objects have not proven very successful (however, see Abadi & Cardelli, A Theory of Objects[53] for formal definitions of many OOP concepts and constructs), and often diverge widely. For example, some definitions focus on mental activities, and some on program structuring. One of the simpler definitions is that OOP is the act of using \"map\" data structures or arrays that can contain functions and pointers to other maps, all with some syntactic and scoping sugar on top. Inheritance can be performed by cloning the maps (sometimes called \"prototyping\").\n\nSee also[edit]\nicon\tComputer programming portal\nComparison of programming languages (object-oriented programming)\nComparison of programming paradigms\nComponent-based software engineering\nDesign by contract\nObject association\nObject database\nObject modeling language\nObject-oriented analysis and design\nObject-relational impedance mismatch (and The Third Manifesto)\nObject-relational mapping\nSystems[edit]\nCADES\nCommon Object Request Broker Architecture (CORBA)\nDistributed Component Object Model\nDistributed Data Management Architecture\nJeroo\nModeling languages[edit]\nIDEF4\nInterface description language\nLepus3\nUML",
          "subparadigms": [
            63,
            62,
            60
          ]
        },
        {
          "pdid": 67,
          "name": "Structured",
          "details": "Structured programming is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by making extensive use of subroutines, block structures, for and while loops—in contrast to using simple tests and jumps such as the go to statement which could lead to \"spaghetti code\" causing difficulty to both follow and maintain.\n\nIt emerged in the late 1950s with the appearance of the ALGOL 58 and ALGOL 60 programming languages,[1] with the latter including support for block structures. Contributing factors to its popularity and widespread acceptance, at first in academia and later among practitioners, include the discovery of what is now known as the structured program theorem in 1966,[2] and the publication of the influential \"Go To Statement Considered Harmful\" open letter in 1968 by Dutch computer scientist Edsger W. Dijkstra, who coined the term \"structured programming\".[3]\n\nStructured programming is most frequently used with deviations that allow for clearer programs in some particular cases, such as when exception handling has to be performed.",
          "subparadigms": [
            64
          ]
        }
      ],
      "programminglanguages": [
        {
          "plid": 1,
          "name": "A+",
          "details": "A+ is an array programming language descendent from the programming language A, which in turn was created to replace APL in 1988.[1] Arthur Whitney developed the \"A\" portion of A+, while other developers at Morgan Stanley extended it, adding a graphical user interface and other language features. A+ was designed for numerically intensive applications, especially those found in financial applications. A+ runs on many Unix variants, including Linux. A+ is a high-level, interactive, interpreted language.\n\nA+ provides an extended set of functions and operators, a graphical user interface with automatic synchronization of widgets and variables, asynchronous execution of functions associated with variables and events, dynamic loading of user compiled subroutines, and other features. A newer graphical user interface has not yet been ported to all supported platforms",
          "type": "compiled"
        },
        {
          "plid": 11,
          "name": "Prolog",
          "details": "Prolog is a general-purpose logic programming language associated with artificial intelligence and computational linguistics.[1][2][3]\n\nProlog has its roots in first-order logic, a formal logic, and unlike many other programming languages, Prolog is declarative: the program logic is expressed in terms of relations, represented as facts and rules. A computation is initiated by running a query over these relations.[4]\n\nThe language was first conceived by a group around Alain Colmerauer in Marseille, France, in the early 1970s and the first Prolog system was developed in 1972 by Colmerauer with Philippe Roussel.[5][6]\n\nProlog was one of the first logic programming languages,[7] and remains the most popular among such languages today, with several free and commercial implementations available. The language has been used for theorem proving,[8] expert systems,[9] as well as its original intended field of use, natural language processing.[10][11] Modern Prolog environments support creating graphical user interfaces, as well as administrative and networked applications.\n\nProlog is well-suited for specific tasks that benefit from rule-based logical queries such as searching databases, voice control systems, and filling templates.",
          "type": "compiled"
        },
        {
          "plid": 13,
          "name": "Clojure",
          "details": "(pronunciation: /ˈkloʊʒɜːr/, like \"closure\"[6]) is a dialect of the Lisp programming language created by Rich Hickey.[7] Clojure is a general-purpose programming language with an emphasis on functional programming.[8] It runs on the Java virtual machine, Common Language Runtime,[9] and JavaScript[10] engines. Like other Lisps, Clojure treats code as data and has a macro system.[11] The current development process is community-driven,[12] overseen by Rich Hickey as its benevolent dictator for life (BDFL).[13]\n\nClojure encourages immutability and immutable data structures. While its type system is entirely dynamic, recent efforts have also sought the implementation of gradual typing.[14] Clojure encourages programmers to be explicit about managing state and identity.[15] This focus on programming with immutable values and explicit progression-of-time constructs is intended to facilitate developing more robust programs, especially multithreaded ones.[16][17]\n\nClojure is used in industry by firms such as Walmart,[18] Puppet Labs,[19] and other large software firms.[20] Commercial support for Clojure is provided by Cognitect.[20] Annual Clojure conferences are organised every year across the globe, the most famous of them being Clojure/conj (US east coast),[21] Clojure/West (US west coast),[22] and EuroClojure (Europe).[23]\n\nThe latest stable version of Clojure is 1.8,[24] released on January 19, 2016. The first stable release was version 1.0, released on May 4, 2009.[25] Clojure is free software released under the Eclipse Public License.[26]\n\nContents  [hide] \n1\tHistory and development process\n2\tDesign philosophy\n3\tFeatures\n4\tPlatforms and popularity\n5\tExamples\n6\tSee also\n7\tReferences\n8\tFurther reading\n9\tExternal links\nHistory and development process[edit]\n\nRich Hickey in San Francisco\nRich Hickey is the creator of the Clojure language.[7] Before Clojure, he developed dotLisp, a similar project based on the .NET Framework,[27] and three earlier attempts to provide interoperability between Lisp and Java: a Java foreign language interface for Common Lisp (jfli),[28] A Foreign Object Interface for Lisp (FOIL),[29] and a Lisp-friendly interface to Java Servlets (Lisplets).[30]\n\nHickey spent about 2½ years working on Clojure before releasing it publicly, much of that time working exclusively on Clojure with no outside funding. At the end of this time, Hickey sent an email announcing the language to some friends in the Common Lisp community.\n\nThe development process is community-driven[12] and is managed at the Clojure Community website.[31] The website contains planning documents and an issue tracker where bugs may be filed. General development discussion occurs at the Clojure Dev Google Group.[32] While anyone can submit bug reports and ideas, to contribute patches one must sign the Clojure Contributor agreement.[33] JIRA tickets are processed by a team of screeners and finally Rich Hickey approves the changes.[34]\n\nDesign philosophy[edit]\nRich Hickey developed Clojure because he wanted a modern Lisp for functional programming, symbiotic with the established Java platform, and designed for concurrency.[16][17][35]\n\nClojure's approach to state is characterized by the concept of identities,[36] which are represented as a series of immutable states over time. Since states are immutable values, any number of workers can operate on them in parallel, and concurrency becomes a question of managing changes from one state to another. For this purpose, Clojure provides several mutable reference types, each having well-defined semantics for the transition between states.",
          "type": "interpreted"
        },
        {
          "plid": 14,
          "name": "Erlang",
          "details": "Erlang (/ˈɜːrlæŋ/ er-lang) is a general-purpose, concurrent, functional programming language. It is also a garbage-collected runtime system. The sequential subset of Erlang supports eager evaluation, single assignment, and dynamic typing. Erlang is known for its designs that are well suited for systems with the following characteristics:\n\nDistributed\nFault-tolerant\nSoft real-time,\nHighly available, non-stop applications\nHot swapping, where code can be changed without stopping a system.[3]\nIt was originally a proprietary language within Ericsson, developed by Joe Armstrong, Robert Virding and Mike Williams in 1986,[4] but was released as open source in 1998.[5][6] Erlang, along with OTP, a collection of middleware and libraries in Erlang, are now supported and maintained by the OTP product unit at Ericsson and have been widely referred to as Erlang/OTP.",
          "type": "compiled"
        },
        {
          "plid": 15,
          "name": "Go",
          "details": "Go (often referred to as golang) is a free and open source[12] programming language created at Google[13] in 2007 by Robert Griesemer, Rob Pike, and Ken Thompson.[10] It is a compiled, statically typed language in the tradition of Algol and C, with garbage collection, limited structural typing,[3] memory safety features and CSP-style concurrent programming features added.[14]\n\nThe language was announced in November 2009; it is used in some of Google's production systems,[15] as well as by other firms. Two major implementations exist: Google's Go compiler, \"gc\", is developed as open source software and targets various platforms including Linux, OS X, Windows, various BSD and Unix versions, and since 2015 also mobile devices, including smartphones.[16] A second compiler, gccgo, is a GCC frontend.[17][18] The \"gc\" toolchain is self-hosting since version 1.5",
          "type": "compiled"
        },
        {
          "plid": 16,
          "name": "Java",
          "details": "Java is a general-purpose computer programming language that is concurrent, class-based, object-oriented,[14] and specifically designed to have as few implementation dependencies as possible. It is intended to let application developers \"write once, run anywhere\" (WORA),[15] meaning that compiled Java code can run on all platforms that support Java without the need for recompilation.[16] Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of computer architecture. As of 2016, Java is one of the most popular programming languages in use,[17][18][19][20] particularly for client-server web applications, with a reported 9 million developers.[21] Java was originally developed by James Gosling at Sun Microsystems (which has since been acquired by Oracle Corporation) and released in 1995 as a core component of Sun Microsystems' Java platform. The language derives much of its syntax from C and C++, but it has fewer low-level facilities than either of them.\n\nThe original and reference implementation Java compilers, virtual machines, and class libraries were originally released by Sun under proprietary licences. As of May 2007, in compliance with the specifications of the Java Community Process, Sun relicensed most of its Java technologies under the GNU General Public License. Others have also developed alternative implementations of these Sun technologies, such as the GNU Compiler for Java (bytecode compiler), GNU Classpath (standard libraries), and IcedTea-Web (browser plugin for applets).\n\nThe latest version is Java 8, which is the only version currently supported for free by Oracle, although earlier versions are supported both by Oracle and other companies on a commercial basis.\n\nJava platform\nMain articles: Java (software platform) and Java virtual machine\n\nJava Control Panel, version 7\nOne design goal of Java is portability, which means that programs written for the Java platform must run similarly on any combination of hardware and operating system with adequate runtime support. This is achieved by compiling the Java language code to an intermediate representation called Java bytecode, instead of directly to architecture-specific machine code. Java bytecode instructions are analogous to machine code, but they are intended to be executed by a virtual machine (VM) written specifically for the host hardware. End users commonly use a Java Runtime Environment (JRE) installed on their own machine for standalone Java applications, or in a web browser for Java applets.\n\nStandard libraries provide a generic way to access host-specific features such as graphics, threading, and networking.\n\nThe use of universal bytecode makes porting simple. However, the overhead of interpreting bytecode into machine instructions makes interpreted programs almost always run more slowly than native executables. However, just-in-time (JIT) compilers that compile bytecodes to machine code during runtime were introduced from an early stage. Java itself is platform-independent, and is adapted to the particular platform it is to run on by a Java virtual machine for it, which translates the Java bytecode into the platform's machine language.[38]\n\nImplementations\nSee also: Free Java implementations\nOracle Corporation is the current owner of the official implementation of the Java SE platform, following their acquisition of Sun Microsystems on January 27, 2010. This implementation is based on the original implementation of Java by Sun. The Oracle implementation is available for Microsoft Windows (still works for XP, while only later versions currently \"publicly\" supported), Mac OS X, Linux and Solaris. Because Java lacks any formal standardization recognized by Ecma International, ISO/IEC, ANSI, or other third-party standards organization, the Oracle implementation is the de facto standard.\n\nThe Oracle implementation is packaged into two different distributions: The Java Runtime Environment (JRE) which contains the parts of the Java SE platform required to run Java programs and is intended for end users, and the Java Development Kit (JDK), which is intended for software developers and includes development tools such as the Java compiler, Javadoc, Jar, and a debugger.\n\nOpenJDK is another notable Java SE implementation that is licensed under the GNU GPL. The implementation started when Sun began releasing the Java source code under the GPL. As of Java SE 7, OpenJDK is the official Java reference implementation.\n\nThe goal of Java is to make all implementations of Java compatible. Historically, Sun's trademark license for usage of the Java brand insists that all implementations be \"compatible\". This resulted in a legal dispute with Microsoft after Sun claimed that the Microsoft implementation did not support RMI or JNI and had added platform-specific features of their own. Sun sued in 1997, and in 2001 won a settlement of US$20 million, as well as a court order enforcing the terms of the license from Sun.[39] As a result, Microsoft no longer ships Java with Windows.\n\nPlatform-independent Java is essential to Java EE, and an even more rigorous validation is required to certify an implementation. This environment enables portable server-side applications.\n\nPerformance\nMain article: Java performance\nPrograms written in Java have a reputation for being slower and requiring more memory than those written in C++.[40][41] However, Java programs' execution speed improved significantly with the introduction of just-in-time compilation in 1997/1998 for Java 1.1,[42] the addition of language features supporting better code analysis (such as inner classes, the StringBuilder class, optional assertions, etc.), and optimizations in the Java virtual machine, such as HotSpot becoming the default for Sun's JVM in 2000. With Java 1.5, the performance was improved with the addition of the java.util.concurrent package, including Lock free implementations of the ConcurrentMaps and other multi-core collections, and it was improved further Java 1.6.\n\nSome platforms offer direct hardware support for Java; there are microcontrollers that can run Java in hardware instead of a software Java virtual machine, and ARM based processors can have hardware support for executing Java bytecode through their Jazelle option (while its support is mostly dropped in current implementations of ARM).\n\nAutomatic memory management\nJava uses an automatic garbage collector to manage memory in the object lifecycle. The programmer determines when objects are created, and the Java runtime is responsible for recovering the memory once objects are no longer in use. Once no references to an object remain, the unreachable memory becomes eligible to be freed automatically by the garbage collector. Something similar to a memory leak may still occur if a programmer's code holds a reference to an object that is no longer needed, typically when objects that are no longer needed are stored in containers that are still in use. If methods for a nonexistent object are called, a \"null pointer exception\" is thrown.[43][44]\n\nOne of the ideas behind Java's automatic memory management model is that programmers can be spared the burden of having to perform manual memory management. In some languages, memory for the creation of objects is implicitly allocated on the stack, or explicitly allocated and deallocated from the heap. In the latter case the responsibility of managing memory resides with the programmer. If the program does not deallocate an object, a memory leak occurs. If the program attempts to access or deallocate memory that has already been deallocated, the result is undefined and difficult to predict, and the program is likely to become unstable and/or crash. This can be partially remedied by the use of smart pointers, but these add overhead and complexity. Note that garbage collection does not prevent \"logical\" memory leaks, i.e., those where the memory is still referenced but never used.\n\nGarbage collection may happen at any time. Ideally, it will occur when a program is idle. It is guaranteed to be triggered if there is insufficient free memory on the heap to allocate a new object; this can cause a program to stall momentarily. Explicit memory management is not possible in Java.\n\nJava does not support C/C++ style pointer arithmetic, where object addresses and unsigned integers (usually long integers) can be used interchangeably. This allows the garbage collector to relocate referenced objects and ensures type safety and security.\n\nAs in C++ and some other object-oriented languages, variables of Java's primitive data types are either stored directly in fields (for objects) or on the stack (for methods) rather than on the heap, as is commonly true for non-primitive data types (but see escape analysis). This was a conscious decision by Java's designers for performance reasons.\n\nJava contains multiple types of garbage collectors. By default,[citation needed] HotSpot uses the parallel scavenge garbage collector. However, there are also several other garbage collectors that can be used to manage the heap. For 90% of applications in Java, the Concurrent Mark-Sweep (CMS) garbage collector is sufficient.[45] Oracle aims to replace CMS with the Garbage-First collector (G1).[46]",
          "type": "compiled"
        },
        {
          "plid": 17,
          "name": "C",
          "details": "C (/ˈsiː/, as in the letter c) is a general-purpose, imperative computer programming language, supporting structured programming, lexical variable scope and recursion, while a static type system prevents many unintended operations. By design, C provides constructs that map efficiently to typical machine instructions, and therefore it has found lasting use in applications that had formerly been coded in assembly language, including operating systems, as well as various application software for computers ranging from supercomputers to embedded systems.\n\nC was originally developed by Dennis Ritchie between 1969 and 1973 at Bell Labs,[5] and used to re-implement the Unix operating system.[6] It has since become one of the most widely used programming languages of all time,[7][8] with C compilers from various vendors available for the majority of existing computer architectures and operating systems. C has been standardized by the American National Standards Institute (ANSI) since 1989 (see ANSI C) and subsequently by the International Organization for Standardization (ISO).",
          "type": "compiled"
        },
        {
          "plid": 18,
          "name": "C++",
          "details": "C++ (pronounced cee plus plus, /ˈsiː plʌs plʌs/) is a general-purpose programming language. It has imperative, object-oriented and generic programming features, while also providing facilities for low-level memory manipulation.\n\nIt was designed with a bias toward system programming and embedded, resource-constrained and large systems, with performance, efficiency and flexibility of use as its design highlights.[5] C++ has also been found useful in many other contexts, with key strengths being software infrastructure and resource-constrained applications,[5] including desktop applications, servers (e.g. e-commerce, web search or SQL servers), and performance-critical applications (e.g. telephone switches or space probes).[6] C++ is a compiled language, with implementations of it available on many platforms and provided by various organizations, including the Free Software Foundation (FSF's GCC), LLVM, Microsoft, Intel and IBM.\n\nC++ is standardized by the International Organization for Standardization (ISO), with the latest standard version ratified and published by ISO in December 2014 as ISO/IEC 14882:2014 (informally known as C++14).[7] The C++ programming language was initially standardized in 1998 as ISO/IEC 14882:1998, which was then amended by the C++03, ISO/IEC 14882:2003, standard. The current C++14 standard supersedes these and C++11, with new features and an enlarged standard library. Before the initial standardization in 1998, C++ was developed by Bjarne Stroustrup at Bell Labs since 1979, as an extension of the C language as he wanted an efficient and flexible language similar to C, which also provided high-level features for program organization.\n\nMany other programming languages have been influenced by C++, including C#, D, Java, and newer versions of C (after 1998).",
          "type": "compiled"
        },
        {
          "plid": 20,
          "name": "Elixir",
          "details": "lixir is a functional, concurrent, general-purpose programming language that runs on the Erlang virtual machine (BEAM). Elixir builds on top of Erlang and shares the same abstractions for building distributed, fault-tolerant applications. Elixir also provides a productive tooling and an extensible design. The latter is supported by compile-time metaprogramming with macros and polymorphism via protocols.[4]\n\nElixir is successfully used in the industry by companies such as Pinterest[5] and Moz.[6] Elixir is also used for web development, by companies such as Bleacher Report and Inverse,[7] and for building embedded-systems.[8][9] The community organizes yearly events in both United States[10][11][12] and Europe[13] as well as minor local events and conferences",
          "type": "dynamic"
        },
        {
          "plid": 21,
          "name": "groovy",
          "details": "Apache Groovy is an object-oriented programming language for the Java platform. It is a dynamic language with features similar to those of Python, Ruby, Perl, and Smalltalk. It can be used as a scripting language for the Java Platform, is dynamically compiled to Java Virtual Machine (JVM) bytecode, and interoperates with other Java code and libraries. Groovy uses a Java-like curly-bracket syntax. Most Java code is also syntactically valid Groovy, although semantics may be different.\n\nGroovy 1.0 was released on January 2, 2007, and Groovy 2.0 in July, 2012. Since version 2, Groovy can also be compiled statically, offering type inference and performance very close to that of Java.[1][2] Groovy 2.4 was the last major release under Pivotal Software's sponsorship which ended in March 2015.[3] Groovy has since changed its governance structure to a Project Management Committee (PMC) in the Apache Software Foundation.",
          "type": "interpreted"
        },
        {
          "plid": 22,
          "name": "JavaScript",
          "details": "In computing, JavaScript (/ˈdʒævəˌskrɪpt/[5]) is a high-level, dynamic, untyped, and interpreted programming language.[6] It has been standardized in the ECMAScript language specification.[7] Alongside HTML and CSS, JavaScript is one of the three core technologies of World Wide Web content production; the majority of websites employ it, and all modern Web browsers support it without the need for plug-ins.[6] JavaScript is prototype-based with first-class functions, making it a multi-paradigm language, supporting object-oriented,[8] imperative, and functional programming styles.[6] It has an API for working with text, arrays, dates and regular expressions, but does not include any I/O, such as networking, storage, or graphics facilities, relying for these upon the host environment in which it is embedded.[7]\n\nAlthough there are strong outward similarities between JavaScript and Java, including language name, syntax, and respective standard libraries, the two are distinct languages and differ greatly in their design. JavaScript was influenced by programming languages such as Self and Scheme.[9]\n\nJavaScript is also used in environments that are not Web-based, such as PDF documents, site-specific browsers, and desktop widgets. Newer and faster JavaScript virtual machines (VMs) and platforms built upon them have also increased the popularity of JavaScript for server-side Web applications. On the client side, developers have traditionally implemented JavaScript as an interpreted language, but more recent browsers perform just-in-time compilation. Programmers also use JavaScript in video-game development, in crafting desktop and mobile applications, and in server-side network programming with run-time environments such as Node.js.",
          "type": "intepreted"
        },
        {
          "plid": 23,
          "name": "OCaml",
          "details": "OCaml (/oʊˈkæməl/ oh-kam-əl), originally known as Objective Caml, is the main implementation of the Caml programming language, created by Xavier Leroy, Jérôme Vouillon, Damien Doligez, Didier Rémy, Ascánder Suárez and others in 1996. A member of the ML language family, OCaml extends the core Caml language with object-oriented constructs.\n\nOCaml's toolset includes an interactive top-level interpreter, a bytecode compiler, a reversible debugger, a package manager (OPAM), and an optimizing native code compiler. It has a large standard library that makes it useful for many of the same applications as Python or Perl, as well as robust modular and object-oriented programming constructs that make it applicable for large-scale software engineering. OCaml is the successor to Caml Light. The acronym \"CAML\" originally stood for Categorical Abstract Machine Language, although OCaml abandons this abstract machine.[1]\n\nOCaml is a free open-source project managed and principally maintained by INRIA. In recent years,[when?] many new languages have drawn elements from OCaml, most notably F# and Scala.",
          "type": "compiled"
        },
        {
          "plid": 25,
          "name": "Objective-J",
          "details": "Objective-J is a programming language developed as part of the Cappuccino web development framework. Its syntax is nearly identical to the Objective-C syntax and it shares with JavaScript the same relationship that Objective-C has with the C programming language: that of being a strict, but small, superset; adding traditional inheritance and Smalltalk/Objective-C style dynamic dispatch. Pure JavaScript, being a prototype-based language, already has a notion of object orientation and inheritance, but Objective-J adds the use of class-based programming to JavaScript.\n\nPrograms written in Objective-J need to be preprocessed before being run by a web browser's JavaScript virtual machine. This step can occur in the web browser at runtime or by a compiler which translates Objective-J programs into pure JavaScript code. The Objective-J compiler is written in JavaScript; consequently, deploying Objective-J programs does not require a web browser plug-in. Objective-J can be compiled and run on Node.js.",
          "type": "compiler"
        },
        {
          "plid": 26,
          "name": "Perl",
          "details": "Perl is a family of high-level, general-purpose, interpreted, dynamic programming languages. The languages in this family include Perl 5 and Perl 6.[6]\n\nThough Perl is not officially an acronym,[7] there are various backronyms in use, the best-known being \"Practical Extraction and Reporting Language\".[8] Perl was originally developed by Larry Wall in 1987 as a general-purpose Unix scripting language to make report processing easier.[9] Since then, it has undergone many changes and revisions. Perl 6, which began as a redesign of Perl 5 in 2000, eventually evolved into a separate language. Both languages continue to be developed independently by different development teams and liberally borrow ideas from one another.\n\nThe Perl languages borrow features from other programming languages including C, shell script (sh), AWK, and sed.[10] They provide powerful text processing facilities without the arbitrary data-length limits of many contemporary Unix commandline tools,[11] facilitating easy manipulation of text files. Perl 5 gained widespread popularity in the late 1990s as a CGI scripting language, in part due to its unsurpassed[12][13][14] regular expression and string parsing abilities.[15]\n\nIn addition to CGI, Perl 5 is used for graphics programming, system administration, network programming, finance, bioinformatics, and other applications. It has been nicknamed \"the Swiss Army chainsaw of scripting languages\" because of its flexibility and power,[16] and possibly also because of its \"ugliness\".[17] In 1998, it was also referred to as the \"duct tape that holds the Internet together\", in reference to both its ubiquitous use as a glue language and its perceived inelegance",
          "type": "interpreted"
        },
        {
          "plid": 27,
          "name": "PHP",
          "details": "PHP is a server-side scripting language designed primarily for web development but also used as a general-purpose programming language. Originally created by Rasmus Lerdorf in 1994,[5] the PHP reference implementation is now produced by The PHP Development Team.[6] PHP originally stood for Personal Home Page,[5] but it now stands for the recursive acronym PHP: Hypertext Preprocessor.[7]\n\nPHP code may be embedded into HTML code, or it can be used in combination with various web template systems, web content management systems and web frameworks. PHP code is usually processed by a PHP interpreter implemented as a module in the web server or as a Common Gateway Interface (CGI) executable. The web server combines the results of the interpreted and executed PHP code, which may be any type of data, including images, with the generated web page. PHP code may also be executed with a command-line interface (CLI) and can be used to implement standalone graphical applications.[8]\n\nThe standard PHP interpreter, powered by the Zend Engine, is free software released under the PHP License. PHP has been widely ported and can be deployed on most web servers on almost every operating system and platform, free of charge.[9]\n\nThe PHP language evolved without a written formal specification or standard until 2014, leaving the canonical PHP interpreter as a de facto standard. Since 2014 work has gone on to create a formal PHP specification.[10]\n\nDuring the 2010s there have been increased efforts towards standardisation and code sharing in PHP applications by projects such as PHP-FIG in the form of PSR-initiatives as well as Composer dependency manager and the Packagist repository.",
          "type": "interpreted"
        },
        {
          "plid": 28,
          "name": "Python",
          "details": "Python is a widely used high-level, general-purpose, interpreted, dynamic programming language.[24][25] Its design philosophy emphasizes code readability, and its syntax allows programmers to express concepts in fewer lines of code than possible in languages such as C++ or Java.[26][27] The language provides constructs intended to enable writing clear programs on both a small and large scale.[28]\n\nPython supports multiple programming paradigms, including object-oriented, imperative and functional programming or procedural styles. It features a dynamic type system and automatic memory management and has a large and comprehensive standard library.[29]\n\nPython interpreters are available for many operating systems, allowing Python code to run on a wide variety of systems. Using third-party tools, such as Py2exe or Pyinstaller,[30] Python code can be packaged into stand-alone executable programs for some of the most popular operating systems, so Python-based software can be distributed to, and used on, those environments with no need to install a Python interpreter.\n\nCPython, the reference implementation of Python, is free and open-source software and has a community-based development model, as do nearly all of its variant implementations. CPython is managed by the non-profit Python Software Foundation.",
          "type": "intepreted"
        },
        {
          "plid": 29,
          "name": "Ruby",
          "details": "Ruby is a dynamic, reflective, object-oriented, general-purpose programming language. It was designed and developed in the mid-1990s by Yukihiro \"Matz\" Matsumoto in Japan.\n\nAccording to its creator, Ruby was influenced by Perl, Smalltalk, Eiffel, Ada, and Lisp.[11] It supports multiple programming paradigms, including functional, object-oriented, and imperative. It also has a dynamic type system and automatic memory management.",
          "type": "intepreted"
        },
        {
          "plid": 30,
          "name": "Scala",
          "details": "Scala (/ˈskɑːlɑː/ skah-lah)[9] is a general-purpose programming language. Scala has full support for functional programming and a strong static type system. Designed to be concise,[10] many of Scala's design decisions were inspired by criticism of Java's shortcomings.[8]\n\nScala source code is intended to be compiled to Java bytecode, so that the resulting executable code runs on a Java virtual machine. Java libraries may be used directly in Scala code and vice versa (language interoperability).[11] Like Java, Scala is object-oriented, and uses a curly-brace syntax reminiscent of the C programming language. Unlike Java, Scala has many features of functional programming languages like Scheme, Standard ML and Haskell, including currying, type inference, immutability, lazy evaluation, and pattern matching. It also has an advanced type system supporting algebraic data types, covariance and contravariance, higher-order types (but not higher-rank types), and anonymous types. Other features of Scala not present in Java include operator overloading, optional parameters, named parameters, raw strings, and no checked exceptions.\n\nThe name Scala is a portmanteau of scalable and language, signifying that it is designed to grow with the demands of its users",
          "type": "compiled"
        },
        {
          "plid": 31,
          "name": "Smalltalk",
          "details": "Smalltalk is an object-oriented, dynamically typed, reflective programming language. Smalltalk was created as the language to underpin the \"new world\" of computing exemplified by \"human–computer symbiosis.\"[2] It was designed and created in part for educational use, more so for constructionist learning, at the Learning Research Group (LRG) of Xerox PARC by Alan Kay, Dan Ingalls, Adele Goldberg, Ted Kaehler, Scott Wallace, and others during the 1970s.\n\nThe language was first generally released as Smalltalk-80. Smalltalk-like languages are in continuing active development and have gathered loyal communities of users around them. ANSI Smalltalk was ratified in 1998 and represents the standard version of Smalltalk.[3]",
          "type": "compiled"
        }
      ],
      "havings": [
        {
          "plid": 1,
          "pdid": 3
        },
        {
          "plid": 20,
          "pdid": 16
        },
        {
          "plid": 13,
          "pdid": 16
        },
        {
          "plid": 14,
          "pdid": 16
        },
        {
          "plid": 14,
          "pdid": 6
        },
        {
          "plid": 15,
          "pdid": 6
        },
        {
          "plid": 15,
          "pdid": 34
        },
        {
          "plid": 15,
          "pdid": 67
        },
        {
          "plid": 17,
          "pdid": 34
        },
        {
          "plid": 17,
          "pdid": 33
        },
        {
          "plid": 17,
          "pdid": 67
        },
        {
          "plid": 18,
          "pdid": 33
        },
        {
          "plid": 18,
          "pdid": 16
        },
        {
          "plid": 18,
          "pdid": 64
        },
        {
          "plid": 21,
          "pdid": 64
        },
        {
          "plid": 21,
          "pdid": 34
        },
        {
          "plid": 22,
          "pdid": 64
        },
        {
          "plid": 22,
          "pdid": 60
        },
        {
          "plid": 22,
          "pdid": 34
        },
        {
          "plid": 22,
          "pdid": 16
        },
        {
          "plid": 23,
          "pdid": 34
        },
        {
          "plid": 23,
          "pdid": 16
        },
        {
          "plid": 23,
          "pdid": 64
        },
        {
          "plid": 25,
          "pdid": 45
        },
        {
          "plid": 25,
          "pdid": 64
        },
        {
          "plid": 25,
          "pdid": 16
        },
        {
          "plid": 25,
          "pdid": 34
        },
        {
          "plid": 26,
          "pdid": 34
        },
        {
          "plid": 26,
          "pdid": 16
        },
        {
          "plid": 26,
          "pdid": 64
        },
        {
          "plid": 26,
          "pdid": 62
        },
        {
          "plid": 26,
          "pdid": 45
        },
        {
          "plid": 26,
          "pdid": 33
        },
        {
          "plid": 27,
          "pdid": 33
        },
        {
          "plid": 27,
          "pdid": 34
        },
        {
          "plid": 27,
          "pdid": 16
        },
        {
          "plid": 27,
          "pdid": 64
        },
        {
          "plid": 27,
          "pdid": 45
        },
        {
          "plid": 28,
          "pdid": 45
        },
        {
          "plid": 28,
          "pdid": 64
        },
        {
          "plid": 28,
          "pdid": 34
        },
        {
          "plid": 28,
          "pdid": 16
        },
        {
          "plid": 28,
          "pdid": 33
        },
        {
          "plid": 29,
          "pdid": 64
        },
        {
          "plid": 29,
          "pdid": 34
        },
        {
          "plid": 29,
          "pdid": 16
        },
        {
          "plid": 29,
          "pdid": 45
        },
        {
          "plid": 30,
          "pdid": 16
        },
        {
          "plid": 30,
          "pdid": 64
        },
        {
          "plid": 30,
          "pdid": 34
        },
        {
          "plid": 31,
          "pdid": 64
        },
        {
          "plid": 16,
          "pdid": 64
        },
        {
          "plid": 16,
          "pdid": 62
        },
        {
          "plid": 16,
          "pdid": 67
        },
        {
          "plid": 16,
          "pdid": 34
        },
        {
          "plid": 16,
          "pdid": 45
        },
        {
          "plid": 11,
          "pdid": 21
        }
      ]
    }
  ]
}